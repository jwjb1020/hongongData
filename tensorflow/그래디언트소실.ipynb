{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150210 (586.76 KB)\n",
      "Trainable params: 150210 (586.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer HeUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "240/240 - 2s - loss: 13.4103 - accuracy: 0.5018 - val_loss: 3.6786 - val_accuracy: 0.3722 - 2s/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "240/240 - 1s - loss: 6.8500 - accuracy: 0.6184 - val_loss: 0.4069 - val_accuracy: 0.8853 - 799ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "240/240 - 1s - loss: 5.8517 - accuracy: 0.6478 - val_loss: 0.5601 - val_accuracy: 0.8646 - 793ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "240/240 - 1s - loss: 6.2159 - accuracy: 0.6946 - val_loss: 1.0564 - val_accuracy: 0.6793 - 821ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "240/240 - 1s - loss: 3.2744 - accuracy: 0.6910 - val_loss: 36.1264 - val_accuracy: 0.1060 - 784ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "240/240 - 1s - loss: 2.7942 - accuracy: 0.7357 - val_loss: 2.3810 - val_accuracy: 0.4735 - 812ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "240/240 - 1s - loss: 3.8446 - accuracy: 0.7196 - val_loss: 0.5706 - val_accuracy: 0.8512 - 798ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "240/240 - 1s - loss: 3.4938 - accuracy: 0.7155 - val_loss: 0.4756 - val_accuracy: 0.8633 - 781ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "240/240 - 1s - loss: 3.0664 - accuracy: 0.6991 - val_loss: 27.3313 - val_accuracy: 0.1070 - 799ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "240/240 - 1s - loss: 3.2705 - accuracy: 0.7413 - val_loss: 10.1086 - val_accuracy: 0.2589 - 766ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "240/240 - 1s - loss: 3.5498 - accuracy: 0.7548 - val_loss: 0.7698 - val_accuracy: 0.7816 - 963ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "240/240 - 1s - loss: 3.4027 - accuracy: 0.7608 - val_loss: 0.3537 - val_accuracy: 0.9107 - 774ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "240/240 - 1s - loss: 3.5742 - accuracy: 0.7440 - val_loss: 0.4683 - val_accuracy: 0.8660 - 773ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "240/240 - 1s - loss: 4.2299 - accuracy: 0.7064 - val_loss: 2.4285 - val_accuracy: 0.4452 - 770ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "240/240 - 1s - loss: 2.7941 - accuracy: 0.7682 - val_loss: 0.7262 - val_accuracy: 0.8176 - 765ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "240/240 - 1s - loss: 2.7167 - accuracy: 0.6934 - val_loss: 0.3483 - val_accuracy: 0.9191 - 770ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "240/240 - 1s - loss: 2.2311 - accuracy: 0.7217 - val_loss: 0.3426 - val_accuracy: 0.9193 - 761ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "240/240 - 1s - loss: 2.0651 - accuracy: 0.7394 - val_loss: 21.1892 - val_accuracy: 0.3103 - 757ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "240/240 - 1s - loss: 4.9537 - accuracy: 0.7533 - val_loss: 0.3795 - val_accuracy: 0.9115 - 764ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "240/240 - 1s - loss: 3.5008 - accuracy: 0.7640 - val_loss: 2.6126 - val_accuracy: 0.6323 - 770ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "240/240 - 1s - loss: 5.9422 - accuracy: 0.7530 - val_loss: 15.2673 - val_accuracy: 0.1978 - 987ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "240/240 - 1s - loss: 2.8574 - accuracy: 0.7400 - val_loss: 0.5879 - val_accuracy: 0.8322 - 791ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "240/240 - 1s - loss: 4.5871 - accuracy: 0.7594 - val_loss: 0.5797 - val_accuracy: 0.8487 - 831ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "240/240 - 1s - loss: 4.6482 - accuracy: 0.7550 - val_loss: 0.3391 - val_accuracy: 0.9224 - 860ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "240/240 - 1s - loss: 3.5297 - accuracy: 0.7592 - val_loss: 0.3666 - val_accuracy: 0.9088 - 893ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "240/240 - 1s - loss: 1.9693 - accuracy: 0.7677 - val_loss: 0.3489 - val_accuracy: 0.9050 - 801ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "240/240 - 1s - loss: 3.7403 - accuracy: 0.7698 - val_loss: 7.1850 - val_accuracy: 0.3443 - 799ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "240/240 - 1s - loss: 5.6356 - accuracy: 0.7826 - val_loss: 0.3165 - val_accuracy: 0.9277 - 789ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "240/240 - 1s - loss: 3.1902 - accuracy: 0.7817 - val_loss: 1.5853 - val_accuracy: 0.6857 - 826ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "240/240 - 1s - loss: 6.4965 - accuracy: 0.7640 - val_loss: 0.4784 - val_accuracy: 0.8928 - 802ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "240/240 - 1s - loss: 2.2896 - accuracy: 0.7778 - val_loss: 0.3840 - val_accuracy: 0.9134 - 1s/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "240/240 - 1s - loss: 1.7956 - accuracy: 0.7912 - val_loss: 1.1854 - val_accuracy: 0.6672 - 794ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "240/240 - 1s - loss: 3.7061 - accuracy: 0.7814 - val_loss: 0.5628 - val_accuracy: 0.8546 - 796ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "240/240 - 1s - loss: 3.5505 - accuracy: 0.8015 - val_loss: 0.4851 - val_accuracy: 0.9078 - 834ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "240/240 - 1s - loss: 2.2781 - accuracy: 0.8203 - val_loss: 1.5643 - val_accuracy: 0.7686 - 787ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "240/240 - 1s - loss: 7.7341 - accuracy: 0.7717 - val_loss: 0.8037 - val_accuracy: 0.8693 - 771ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "240/240 - 1s - loss: 2.5489 - accuracy: 0.8138 - val_loss: 0.3422 - val_accuracy: 0.9182 - 766ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "240/240 - 1s - loss: 5.8351 - accuracy: 0.8061 - val_loss: 0.2863 - val_accuracy: 0.9265 - 776ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "240/240 - 1s - loss: 5.0753 - accuracy: 0.7905 - val_loss: 0.3403 - val_accuracy: 0.9210 - 770ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "240/240 - 1s - loss: 2.6088 - accuracy: 0.8188 - val_loss: 0.4495 - val_accuracy: 0.8907 - 768ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "240/240 - 1s - loss: 3.4565 - accuracy: 0.7940 - val_loss: 0.3231 - val_accuracy: 0.9239 - 978ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "240/240 - 1s - loss: 4.3823 - accuracy: 0.7969 - val_loss: 0.4017 - val_accuracy: 0.9187 - 777ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "240/240 - 1s - loss: 4.8355 - accuracy: 0.7836 - val_loss: 7.2731 - val_accuracy: 0.3997 - 767ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "240/240 - 1s - loss: 3.7077 - accuracy: 0.8162 - val_loss: 107.5326 - val_accuracy: 0.2787 - 777ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "240/240 - 1s - loss: 3.3962 - accuracy: 0.7966 - val_loss: 0.4051 - val_accuracy: 0.9247 - 797ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "240/240 - 1s - loss: 6.6228 - accuracy: 0.8266 - val_loss: 0.9862 - val_accuracy: 0.7768 - 766ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "240/240 - 1s - loss: 4.0572 - accuracy: 0.8102 - val_loss: 0.4752 - val_accuracy: 0.8827 - 804ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "240/240 - 1s - loss: 2.5957 - accuracy: 0.8134 - val_loss: 0.2411 - val_accuracy: 0.9406 - 786ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "240/240 - 1s - loss: 4.2741 - accuracy: 0.7953 - val_loss: 0.3264 - val_accuracy: 0.9297 - 771ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "240/240 - 1s - loss: 1.8753 - accuracy: 0.8234 - val_loss: 4.4082 - val_accuracy: 0.5822 - 798ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "240/240 - 1s - loss: 4.1117 - accuracy: 0.8223 - val_loss: 4.6678 - val_accuracy: 0.4347 - 996ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "240/240 - 1s - loss: 3.9794 - accuracy: 0.8002 - val_loss: 0.7305 - val_accuracy: 0.8627 - 776ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "240/240 - 1s - loss: 2.7848 - accuracy: 0.8365 - val_loss: 0.2552 - val_accuracy: 0.9463 - 786ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "240/240 - 1s - loss: 4.9757 - accuracy: 0.7799 - val_loss: 0.6598 - val_accuracy: 0.8663 - 793ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "240/240 - 1s - loss: 5.5476 - accuracy: 0.8303 - val_loss: 0.4730 - val_accuracy: 0.9056 - 794ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "240/240 - 1s - loss: 3.7987 - accuracy: 0.8115 - val_loss: 0.4720 - val_accuracy: 0.9177 - 784ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "240/240 - 1s - loss: 3.3535 - accuracy: 0.8313 - val_loss: 0.3981 - val_accuracy: 0.9210 - 852ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "240/240 - 1s - loss: 5.7646 - accuracy: 0.8019 - val_loss: 0.3434 - val_accuracy: 0.9306 - 875ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "240/240 - 1s - loss: 2.1356 - accuracy: 0.8173 - val_loss: 0.2575 - val_accuracy: 0.9421 - 845ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "240/240 - 1s - loss: 8.0825 - accuracy: 0.8355 - val_loss: 0.4183 - val_accuracy: 0.9028 - 851ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "240/240 - 1s - loss: 2.8399 - accuracy: 0.8138 - val_loss: 0.3057 - val_accuracy: 0.9355 - 1s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "240/240 - 1s - loss: 2.8973 - accuracy: 0.8185 - val_loss: 0.3230 - val_accuracy: 0.9230 - 882ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "240/240 - 1s - loss: 3.9788 - accuracy: 0.8248 - val_loss: 8.1514 - val_accuracy: 0.2878 - 850ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "240/240 - 1s - loss: 1.5547 - accuracy: 0.8281 - val_loss: 11.5355 - val_accuracy: 0.3144 - 801ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "240/240 - 1s - loss: 3.9920 - accuracy: 0.8302 - val_loss: 0.2731 - val_accuracy: 0.9394 - 859ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "240/240 - 1s - loss: 2.7929 - accuracy: 0.7975 - val_loss: 0.4630 - val_accuracy: 0.8637 - 805ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "240/240 - 1s - loss: 2.3951 - accuracy: 0.8367 - val_loss: 0.5058 - val_accuracy: 0.8530 - 834ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "240/240 - 1s - loss: 2.3807 - accuracy: 0.8269 - val_loss: 0.3177 - val_accuracy: 0.9283 - 832ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "240/240 - 1s - loss: 1.3042 - accuracy: 0.8166 - val_loss: 0.3285 - val_accuracy: 0.9238 - 1s/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "240/240 - 1s - loss: 1.6291 - accuracy: 0.8375 - val_loss: 1.0964 - val_accuracy: 0.7853 - 974ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "240/240 - 1s - loss: 2.1459 - accuracy: 0.8342 - val_loss: 9.7812 - val_accuracy: 0.4192 - 1s/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "240/240 - 1s - loss: 2.9622 - accuracy: 0.8292 - val_loss: 4.1519 - val_accuracy: 0.4641 - 829ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "240/240 - 1s - loss: 1.6057 - accuracy: 0.8177 - val_loss: 0.2996 - val_accuracy: 0.9270 - 964ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "240/240 - 1s - loss: 5.1300 - accuracy: 0.8264 - val_loss: 0.2679 - val_accuracy: 0.9369 - 861ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "240/240 - 1s - loss: 2.0435 - accuracy: 0.8649 - val_loss: 4.0173 - val_accuracy: 0.3442 - 793ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "240/240 - 1s - loss: 2.2559 - accuracy: 0.8177 - val_loss: 0.3525 - val_accuracy: 0.9392 - 817ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "240/240 - 1s - loss: 1.2196 - accuracy: 0.8450 - val_loss: 1.8859 - val_accuracy: 0.8229 - 789ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "240/240 - 1s - loss: 3.2030 - accuracy: 0.8331 - val_loss: 0.3316 - val_accuracy: 0.9277 - 785ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "240/240 - 1s - loss: 1.5673 - accuracy: 0.8475 - val_loss: 0.3289 - val_accuracy: 0.9270 - 798ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "240/240 - 1s - loss: 3.0089 - accuracy: 0.8404 - val_loss: 34.9235 - val_accuracy: 0.2672 - 791ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "240/240 - 1s - loss: 3.1598 - accuracy: 0.8312 - val_loss: 0.3062 - val_accuracy: 0.9358 - 1s/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "240/240 - 1s - loss: 2.0604 - accuracy: 0.8487 - val_loss: 4.1303 - val_accuracy: 0.4015 - 847ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "240/240 - 1s - loss: 3.0989 - accuracy: 0.8682 - val_loss: 1.7359 - val_accuracy: 0.8433 - 817ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "240/240 - 1s - loss: 4.6352 - accuracy: 0.8183 - val_loss: 0.3224 - val_accuracy: 0.9227 - 860ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "240/240 - 1s - loss: 2.2164 - accuracy: 0.8653 - val_loss: 0.4067 - val_accuracy: 0.9237 - 833ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "240/240 - 1s - loss: 3.0026 - accuracy: 0.8230 - val_loss: 0.3552 - val_accuracy: 0.9231 - 793ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "240/240 - 1s - loss: 2.1367 - accuracy: 0.8599 - val_loss: 0.3455 - val_accuracy: 0.9169 - 833ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "240/240 - 1s - loss: 4.5568 - accuracy: 0.8386 - val_loss: 0.6361 - val_accuracy: 0.8953 - 797ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "240/240 - 1s - loss: 3.5171 - accuracy: 0.8643 - val_loss: 1.4336 - val_accuracy: 0.8312 - 802ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "240/240 - 1s - loss: 3.0020 - accuracy: 0.8248 - val_loss: 0.3404 - val_accuracy: 0.9384 - 787ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "240/240 - 1s - loss: 5.8924 - accuracy: 0.8201 - val_loss: 0.7790 - val_accuracy: 0.9032 - 1s/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "240/240 - 1s - loss: 4.4396 - accuracy: 0.8592 - val_loss: 0.6240 - val_accuracy: 0.9057 - 873ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "240/240 - 1s - loss: 1.5465 - accuracy: 0.8565 - val_loss: 1.0560 - val_accuracy: 0.8088 - 853ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "240/240 - 1s - loss: 2.0817 - accuracy: 0.8426 - val_loss: 0.4752 - val_accuracy: 0.9285 - 847ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "240/240 - 1s - loss: 1.5594 - accuracy: 0.8503 - val_loss: 0.6919 - val_accuracy: 0.8683 - 815ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "240/240 - 1s - loss: 3.1712 - accuracy: 0.8399 - val_loss: 0.4903 - val_accuracy: 0.9007 - 818ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "240/240 - 1s - loss: 4.0695 - accuracy: 0.8287 - val_loss: 19.1510 - val_accuracy: 0.2826 - 869ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "240/240 - 1s - loss: 1.9259 - accuracy: 0.8553 - val_loss: 0.5333 - val_accuracy: 0.8900 - 848ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "240/240 - 1s - loss: 2.6746 - accuracy: 0.8540 - val_loss: 1.3428 - val_accuracy: 0.7475 - 822ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "240/240 - 1s - loss: 3.6899 - accuracy: 0.8422 - val_loss: 0.3629 - val_accuracy: 0.9338 - 793ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#1\n",
    "(x_train, y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "#2\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "#3: one hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "#build a model\n",
    "init = tf.keras.initializers.he_uniform()\n",
    "act = tf.keras.layers.LeakyReLU(alpha=0.3)\n",
    "n=100\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.Dense(units=n,activation=act,kernel_initializer=init))\n",
    "model.add(tf.keras.layers.Dense(units=n,activation=act,kernel_initializer=init))\n",
    "model.add(tf.keras.layers.Dense(units=n,activation=act,kernel_initializer=init))\n",
    "model.add(tf.keras.layers.Dense(units=n,activation=act,kernel_initializer=init))\n",
    "model.add(tf.keras.layers.Dense(units=n,activation=act,kernel_initializer=init))\n",
    "model.add(tf.keras.layers.Dense(units=n,activation=act,kernel_initializer=init))\n",
    "model.add(tf.keras.layers.Dense(units=n,activation=act,kernel_initializer=init))\n",
    "model.add(tf.keras.layers.Dense(units=n,activation=act,kernel_initializer=init))\n",
    "model.add(tf.keras.layers.Dense(units=10,activation=\"softmax\",kernel_initializer=init))\n",
    "model.summary()\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#5\n",
    "import os\n",
    "path = \"/Users/user/Desktop/\"\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "logdir = path + \"3203\"\n",
    "\n",
    "callback = tf.keras.callbacks.TensorBoard(log_dir=logdir,update_freq=\"epoch\",\n",
    "                                          histogram_freq=10, write_images=True) \n",
    "ret = model.fit(x_train,y_train, epochs=100, batch_size=200,\n",
    "                validation_split=0.2,verbose=2,callbacks=[callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
